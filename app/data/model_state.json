{
  "snapshot_timestamp": "2025-12-16T02:00:00Z",
  "source": "synthetic-simulator",
  "models": [
    {
      "model_id": "gpt-3.5-turbo",
      "version": "0613",
      "status": "healthy",
      "latency_ms": 120,
      "error_rate": 0.01,
      "rate_limit_remaining": 8000,
      "backend": "aws",
      "cost_per_1k": 0.0015,
      "context_window": 4096,
      "tasks_supported": ["chat", "reasoning", "summarization"],
      "last_updated": "2025-12-15T01:00:00Z",
      "max_throughput_rps": 50,
      "spot_instance_available": true,
      "maintenance_window": null,
      "quality_score_trend": [-0.01, 0.00, 0.01, -0.02, 0.00]
    },
    {
      "model_id": "gpt-4",
      "version": "2024-12-preview",
      "status": "degraded",
      "latency_ms": 500,
      "error_rate": 0.06,
      "rate_limit_remaining": 2000,
      "backend": "aws",
      "cost_per_1k": 0.06,
      "context_window": 128000,
      "tasks_supported": ["chat", "code-gen", "qa", "reasoning"],
      "last_updated": "2025-12-15T01:00:00Z",
      "max_throughput_rps": 10,
      "spot_instance_available": false,
      "maintenance_window": "2025-12-16T02:00:00Z",
      "quality_score_trend": [-0.03, -0.02, -0.01, -0.04, -0.05]
    },
    {
      "model_id": "claude-2.1",
      "version": "2.1.0",
      "status": "healthy",
      "latency_ms": 180,
      "error_rate": 0.015,
      "rate_limit_remaining": 5000,
      "backend": "neocloud",
      "cost_per_1k": 0.008,
      "context_window": 100000,
      "tasks_supported": ["summarization", "qa", "chat"],
      "last_updated": "2025-12-14T23:30:00Z",
      "max_throughput_rps": 25,
      "spot_instance_available": true,
      "maintenance_window": null,
      "quality_score_trend": [0.00, 0.01, 0.01, 0.00, 0.01]
    },
    {
      "model_id": "claude-3-opus",
      "version": "3.0.0",
      "status": "healthy",
      "latency_ms": 250,
      "error_rate": 0.02,
      "rate_limit_remaining": 6000,
      "backend": "aws",
      "cost_per_1k": 0.015,
      "context_window": 200000,
      "tasks_supported": ["chat", "qa", "reasoning", "summarization"],
      "last_updated": "2025-12-15T00:45:00Z",
      "max_throughput_rps": 20,
      "spot_instance_available": true,
      "maintenance_window": null,
      "quality_score_trend": [0.00, 0.01, 0.00, -0.01, 0.00]
    },
    {
      "model_id": "mistral-7b",
      "version": "instruct-v0.2",
      "status": "down",
      "latency_ms": null,
      "error_rate": null,
      "rate_limit_remaining": 0,
      "backend": "k8s",
      "cost_per_1k": 0.002,
      "context_window": 8000,
      "tasks_supported": ["qa", "reasoning"],
      "last_updated": "2025-12-13T20:00:00Z",
      "max_throughput_rps": 15,
      "spot_instance_available": false,
      "maintenance_window": "2025-12-17T01:00:00Z",
      "quality_score_trend": [null, null, null, null, null]
    },
    {
      "model_id": "mixtral-8x7b",
      "version": "v1.0",
      "status": "healthy",
      "latency_ms": 140,
      "error_rate": 0.01,
      "rate_limit_remaining": 7000,
      "backend": "k8s",
      "cost_per_1k": 0.003,
      "context_window": 32000,
      "tasks_supported": ["reasoning", "classification"],
      "last_updated": "2025-12-15T00:15:00Z",
      "max_throughput_rps": 45,
      "spot_instance_available": true,
      "maintenance_window": null,
      "quality_score_trend": [0.02, 0.01, 0.00, 0.00, 0.01]
    },
    {
      "model_id": "llama-2-13b",
      "version": "chat-v1",
      "status": "healthy",
      "latency_ms": 160,
      "error_rate": 0.02,
      "rate_limit_remaining": 6500,
      "backend": "neocloud",
      "cost_per_1k": 0.0025,
      "context_window": 4096,
      "tasks_supported": ["chat", "reasoning"],
      "last_updated": "2025-12-15T00:55:00Z",
      "max_throughput_rps": 30,
      "spot_instance_available": false,
      "maintenance_window": null,
      "quality_score_trend": [-0.01, 0.00, 0.00, 0.01, -0.01]
    },
    {
      "model_id": "llama-3-70b",
      "version": "chat-v0.9",
      "status": "healthy",
      "latency_ms": 220,
      "error_rate": 0.01,
      "rate_limit_remaining": 4000,
      "backend": "aws",
      "cost_per_1k": 0.01,
      "context_window": 8000,
      "tasks_supported": ["chat", "qa", "code-gen"],
      "last_updated": "2025-12-15T01:00:00Z",
      "max_throughput_rps": 18,
      "spot_instance_available": false,
      "maintenance_window": null,
      "quality_score_trend": [0.00, 0.01, 0.00, -0.01, -0.02]
    },
    {
      "model_id": "gemma-7b",
      "version": "v0.1",
      "status": "degraded",
      "latency_ms": 450,
      "error_rate": 0.04,
      "rate_limit_remaining": 3000,
      "backend": "k8s",
      "cost_per_1k": 0.001,
      "context_window": 8192,
      "tasks_supported": ["chat", "classification"],
      "last_updated": "2025-12-14T23:00:00Z",
      "max_throughput_rps": 10,
      "spot_instance_available": false,
      "maintenance_window": "2025-12-18T01:30:00Z",
      "quality_score_trend": [-0.02, -0.01, 0.00, -0.02, -0.03]
    },
    {
      "model_id": "falcon-180b",
      "version": "v1.1",
      "status": "healthy",
      "latency_ms": 300,
      "error_rate": 0.015,
      "rate_limit_remaining": 3500,
      "backend": "neocloud",
      "cost_per_1k": 0.009,
      "context_window": 2048,
      "tasks_supported": ["chat", "summarization", "qa"],
      "last_updated": "2025-12-15T00:50:00Z",
      "max_throughput_rps": 20,
      "spot_instance_available": true,
      "maintenance_window": null,
      "quality_score_trend": [0.01, 0.00, -0.01, 0.00, 0.01]
    }
  ]
}
